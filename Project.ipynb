{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI 100: Group Project\n",
    "\n",
    "# TODO: Insert project title\n",
    "\n",
    "\n",
    "## Classification of Facebook Posts\n",
    "\n",
    "#### Introduction:\n",
    "\n",
    "The rapid change of technology has greatly transformed the business world. Social media platforms have become the best place for businesses to advertise their brands through customer engagement. \n",
    "Our study focuses on the biggest social network worldwide, Facebook, with over 2.7 billion monthly active users ((Statista, 2021). \n",
    "\n",
    "The dataset *Facebook performance metrics* (Moro et al., 2016) contains data related to posts published throughout the year 2014 on a renowned cosmetics brand's Facebook page. Post information such as type (photo, status, link, or video), time posted (month, day of week, and hour), user engagement (comments, likes, and shares), impressions on each post (too many columns to list here), and whether the post was paid or unpaid is included in the dataset. This project proposes to use all relevant columns from this dataset to determine the type of a brand's Facebook post. We will determine which of these metrics are relivant in our cleaning and exploration of the data.\n",
    "\n",
    "TODO: (from prop feedback) Please provide some background info, so that someone unfamiliar with it will be prepared to understand the rest of your proposal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: EXPLICITELY STATE OUR RESEARCH QUESTION HERE!!!\n",
    "**from proposal feedback, Please state your proposal question clearly and in a form of a \"predictive question\"**\n",
    "Our study focuses on predicting post type given "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preliminary exploratory data analysis:\n",
    "\n",
    "We begin by loading the relevant libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries for preliminary data analysis:\n",
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(readxl)\n",
    "library(tidymodels)\n",
    "library(GGally)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell loads the dataset into R; as the dataset on the web is contained in a zip folder, the .csv file was manually extracted and pushed to the working Github repository.\n",
    "\n",
    "The dataset is already in tidy format. The column headings were made more usable by removing spaces and shortening longer headings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displays first and last 8 rows of the dataset\n",
    "options(repr.matrix.max.rows = 16)\n",
    "# Set the seed\n",
    "set.seed(123)\n",
    "\n",
    "# Load the data in\n",
    "fb_data_raw <- read_csv2(\"https://gist.githubusercontent.com/KolCrooks/691e5890b6747b4777d6032f019b2c0f/raw/20629a5da3d5a7683e3071798876f3e4b204fbbb/fb_data.csv\",  col_types = cols())\n",
    "\n",
    "fb_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Na Rows:\n",
    "sum(is.na(fb_data_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: EXPLAIN WHY WE CONVERT COMMENT LIKE AND SHARE TO PERCENTS\n",
    "Since we are going to be working with type, category, post month, post_weekday, and post hours as a categorical statistical variables, \n",
    "we are converting them to factors using the function `as_factor`. In addition, we realized that we had 6 NAs in our data set, so we are using `na.omit` function to remove all the NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data:\n",
    "fb_data_clean_cols <- fb_data_raw\n",
    "colnames(fb_data_clean_cols) <- c(\"page_likes\", \"type\", \"category\", \"post_month\", \"post_weekday\", \"post_hour\", \"paid\", \"reach\", \n",
    "      \"impressions\", \"engaged_users\", \"post_consumers\", \"post_consumptions\", \"impressions_by_people_that_liked_page\", \n",
    "      \"reach_by_people_that_like_page\", \"people_liked_and_engaged\", \"comments\", \"likes\", \"shares\", \"interactions\")\n",
    "fb_data_clean <- fb_data_clean_cols %>% \n",
    "        mutate(type = as_factor(type)) %>% \n",
    "        mutate(category = as_factor(category)) %>% \n",
    "        mutate(post_month = as_factor(post_month)) %>% \n",
    "        mutate(post_weekday = as_factor(post_weekday)) %>% \n",
    "        mutate(post_hour = as_factor(post_hour)) %>% \n",
    "        na.omit()\n",
    "\n",
    "fb_data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if all NAs are removed\n",
    "#Na Rows:\n",
    "sum(is.na(fb_data_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: EXPLAIN WHY THE STRATA IS \"TYPE\"\n",
    "# TODO: EXPLAIN WHY WE CHOSE 75%\n",
    "**\"Why have you decided to use 75% of the dataset as the training data?\"**\n",
    "<p> Here we are splitting our data into training and testing sets using `initial_split`. In order to get a more accurate calculation of our model performance, we choose to use a larger training data of 75% while keeping the remaining 25% for testing. As we want to classify facebook post type, we pass `type` to `strata` argument in initial splitting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data:\n",
    "fb_split <- initial_split(fb_data_clean, prop = 0.5, strata = type)\n",
    "fb_train <- training(fb_split)\n",
    "fb_test <- testing(fb_split)\n",
    "\n",
    "fb_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: include Plot title!\n",
    "**The plot does not include a title. For the report, please make sure you are labelling your tables and plots.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting our predictors\n",
    "\n",
    "To figure out which predictors we want to use, we will use `ggpairs` to determine how well each column can predict post type. To do this we will look at how different each post type's box plot is when compared with the predictor.  Before looking at the ggpairs plot, we want to take out the columns that we know wouldn't work. This is because we don't need ggpairs to know that they wouldn't work, and it would help to reduce clutter in the plot while allowing us to better look at the remaing predictors.\n",
    "\n",
    "\n",
    "The main predictors that we know we can't use are coulmns with factors. This includes the time based columns `post_month`, `post_weekday`, and `post_hour`, and also `category`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns before selection\n",
    "colnames(fb_data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_data_selected1 <- fb_train %>% \n",
    "            select(-post_month, -post_weekday, -post_hour, -category) %>%\n",
    "            select(type, page_likes, paid:interactions) # reorder the df so that type is first, so that we can display only that row\n",
    "fb_data_selected1\n",
    "\n",
    "#         mutate(comment_percent = comments / interactions) %>% \n",
    "#         mutate(like_percent = likes / interactions) %>% \n",
    "#         mutate(share_percent = shares / interactions) %>% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options(repr.plot.height = 5, repr.plot.width = 30)\n",
    "fb_select_plot <- fb_data_selected1 %>% \n",
    "    ggpairs() +\n",
    "    ggtitle(\"Distribution of different factors\")\n",
    "    theme(text = element_text(size=14))\n",
    "\n",
    "# Select just the top row because it is the only thing that we are trt\n",
    "fb_select_plot$nrow <- 1\n",
    "fb_select_plot$yAxisLabels <- fb_select_plot$yAxisLabels[1]\n",
    "fb_select_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Looking at this plot, it might be better to say which predictors wouldn't be good classifiers for our prediction:\n",
    "- `impressions` will not a great classifier because the difference in most columns look the same, meaning there is less variation in the data. While the video boxplot does look different from the rest, the outliers from other ones also occupy similar space.\n",
    "- `impressions_by_people_that_liked_page` looks very bad with each box plot looking like just a line.\n",
    "- `comments`, `likes`, `shares`, and `interactions` look like they have similar problems as `impressions`.\n",
    "\n",
    "We think that some of these might actually be promissing but the scale is so small that it is hard to see any differences. Something we can do is scale a predictor based on another one.\n",
    "\n",
    "With `comments`, `likes`, `shares`, and `interactions`, all of these are related in that `interactions` is the sum of the `comments`, `likes`, and `shares` on each post. We can turn these into ratios by turing `comments`, `likes`, and `shares`, into percentages of the total interactions. These are better than the raw values because the raw values are a measure of the popularity of the page, and not characteristics of the post type. This will normalize the data, allowing for the model to be effective in classifying posts for any page size. \n",
    "\n",
    "# Talk about why the columns we picked are good\n",
    "\n",
    "# MAYBE LOOK INTO `impressions` AND `impressions_by_people_that_liked_page`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_data_selected2 <- fb_data_selected1 %>% \n",
    "            select(-impressions, -impressions_by_people_that_liked_page) %>% \n",
    "            mutate(comment_percent = comments / interactions) %>% \n",
    "            mutate(like_percent = likes / interactions) %>% \n",
    "            mutate(share_percent = shares / interactions) %>% \n",
    "            select(-comments, -likes, -shares, -interactions) # We don't need these anymore because they have been scaled\n",
    "fb_data_selected2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.height = 5, repr.plot.width = 30)\n",
    "fb_select_plot2 <- fb_data_selected2 %>% \n",
    "    ggpairs() +\n",
    "    ggtitle(\"Distribution of different factors for Second Selection Set\")\n",
    "    theme(text = element_text(size=14))\n",
    "\n",
    "# Select just the top row because it is the only thing that we are trt\n",
    "fb_select_plot2$nrow <- 1\n",
    "fb_select_plot2$yAxisLabels <- fb_select_plot2$yAxisLabels[1]\n",
    "fb_select_plot2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`comment_percent`, `like_percent`, and `share_percent` look very different now. `comment_percent` still does not look like it would be good, but `like_percent`, and `share_percent` seem like they could be good as the variance for each box plot looks different enough where you can tell them apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_data_selected <- fb_data_selected2 %>% \n",
    "            select(-comment_percent)\n",
    "fb_data_selected2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something else we want to think about is there any hidden predictors that we can get from combining other predictors? \n",
    "# Should we include this part?\n",
    "When doing some research on this dataset, we found that some people created a engagement ratio factor that is `interactions` / `reach`. When we ggpairs this with type, we get this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_select_plot3 <- fb_data_clean %>%\n",
    "    mutate(engagement_ratio = interactions / reach) %>% \n",
    "    select(type, engagement_ratio) %>% \n",
    "    ggpairs() +\n",
    "    ggtitle(\"Distribution of different factors for Second Selection Set\")\n",
    "    theme(text = element_text(size=14))\n",
    "\n",
    "# Select just the top row because it is the only thing that we are trt\n",
    "fb_select_plot3$nrow <- 1\n",
    "fb_select_plot3$yAxisLabels <- fb_select_plot$yAxisLabels[1]\n",
    "fb_select_plot3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks promising so we will add this as a factor that we want to look at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Preliminary Summary Tables:\n",
    "\n",
    "Tables were constructed to gain an initial summary of the data. Table *summary_table1* groups posts by type and computes the total posts, total interactions (including all likes, comments, shares), maximum interactions, and number of paid posts for each type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_table1 = fb_train %>% \n",
    "    group_by(type) %>%\n",
    "    summarize(total_of_type = n())\n",
    "\n",
    "summary_table1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the number of different posts, it is clear that we need to upsample the data. This does raise some concerns about how well it will be able to predict some types (mainly the type `video`), but we are confident that we can still get good results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selected Columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols <- tibble(col_name = append(colnames(fb_data_selected), 'engagement_ratio'))\n",
    "selected_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary visualizations:\n",
    "\n",
    "# TODO: should we create visualizations? I think the ggpairs exploration should be enough but who knows. - Kol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods:\n",
    "\n",
    "Our analysis will use the following input columns of the original dataset: type `page_likes`, `paid`, `reach`, `engaged_users`, `post_consumers`, `post_consumptions`, `reach_by_people_that_like_page`, and `people_liked_and_engaged`. We will also be using the generated columns `comment_percent`, `like_percent`, `share_percent`, and `engagement_ratio`.\n",
    "\n",
    "\n",
    "Our aim is to use the K-nearest neighbours algorithm to generate a classification model which will classify a post by type (photo, status, link, or video).\n",
    "\n",
    "To visualize our results, we plan to use a confusion matrix. This will display how often our classification model labels a post correctly, and how often each label gets confused with another. We will also use bar charts to visualize relevant and intermediate results; e.g., we will create a bar chart with post type on the x-axis and interactions on the y-axis, filling out the bars with proportional values of the type of each interaction. As part of the tuning step of creating the model, we can create a line chart to show us the optimal K value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected outcomes and significance:\n",
    "\n",
    "This analysis hopes to define a relationship between type of post (i.e., photo, status, link, or video) and ratio of the corresponding post’s interaction type. It is expected that videos and photos, for example, may have higher percentages of interactions that are comments and/or likes when compared to a link or status.\n",
    "\n",
    "This classification application for labeling a post’s type could be helpful in identifying the types of reactions that a post might receive. It is possible that we find images get the most likes, while statuses get the most comments. Knowing how these metrics indicate the type could lead to better targeted ad campaigns that look for a certain type of user engagement.\n",
    "\n",
    "Future questions following from this analysis may include:\n",
    "- Do paid posts generate more traffic than unpaid posts?\n",
    "- Does the category of a post (i.e., “action”, “product”, or “inspiration” classification) affect the overall and/or ratio of interactions on a post?\n",
    "- Do posts with more interactions overall correlate with increases in users liking a company’s Facebook page? \n",
    "\n",
    "In examining the data for classification, it is also expected that trends may emerge which could in the future be used to predict post engagement. This predictive knowledge could be used by companies looking to grow their social media reach, as they may more accurately tailor their posts to yield higher engagement before publishing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsample_recipe <- recipe(type ~ ., data = fb_train) %>% \n",
    "                    step_upsample(type, over_ratio = 1, skip = FALSE ) %>% \n",
    "                    prep()\n",
    "\n",
    "\n",
    "\n",
    "fb_train_upsampled <- upsample_recipe %>% bake(fb_train)\n",
    "fb_train_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the tune spec\n",
    "knn_spec_tune <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) %>% \n",
    "            set_engine(\"kknn\") %>% \n",
    "            set_mode(\"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the recipe\n",
    "fb_recipe <- recipe(type ~  page_likes +\n",
    "                            paid +\n",
    "                            reach +\n",
    "                            engaged_users +\n",
    "#                             post_consumers +\n",
    "#                             post_consumptions +\n",
    "#                             reach_by_people_that_like_page +\n",
    "                            people_liked_and_engaged \n",
    "#                             likes +\n",
    "#                             shares +\n",
    "#                             interactions\n",
    "#                             engagement_ratio\n",
    "                    , data = fb_train_upsampled) %>%\n",
    "#                 step_mutate(likes = likes / interactions,\n",
    "#                             share_percent = shares / interactions) %>%  #,\n",
    "#                             engagement_ratio = interactions / reach) %>%\n",
    "#                 step_upsample(type, over_ratio = 1, skip = FALSE) %>%\n",
    "                step_scale(all_predictors()) %>% \n",
    "                step_center(all_predictors()) %>% \n",
    "                prep()\n",
    "\n",
    "fb_recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show that we are using the correct columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baked_fb <- bake(fb_recipe, fb_train_upsampled)\n",
    "baked_fb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show that data has been upsampled and balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baked_fb %>% \n",
    "    group_by(type) %>% \n",
    "    summarize(n = n())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune the model:\n",
    "\n",
    "# Why does output have neighbors 1..15 where it skips some?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vfolds with v\n",
    "fb_vfold <- vfold_cv(baked_fb, v = 20, strata = type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridvals = tibble(neighbors = 1:20)\n",
    "\n",
    "fb_fit <- workflow() %>% \n",
    "        add_recipe(fb_recipe) %>% \n",
    "        add_model(knn_spec_tune) %>% \n",
    "        tune_grid(resamples = fb_vfold, grid = gridvals) %>% \n",
    "        collect_metrics()\n",
    "\n",
    "fb_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_filtered <- fb_fit %>% filter(.metric == \"accuracy\")\n",
    "\n",
    "fb_filtered %>% ggplot(aes(x = neighbors, y = mean)) +\n",
    "            geom_point() +\n",
    "            geom_line() +\n",
    "            scale_x_continuous(breaks = 1:20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 2) %>%\n",
    "  set_engine(\"kknn\") %>%\n",
    "  set_mode(\"classification\")\n",
    "\n",
    "knn_fit <- workflow() %>%\n",
    "  add_recipe(fb_recipe) %>%\n",
    "  add_model(knn_spec) %>%\n",
    "  fit(data = baked_fb)\n",
    "knn_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_test_predictions <- predict(knn_fit, fb_test) %>%\n",
    "  bind_cols(fb_test)\n",
    "fb_test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_test_predictions %>%\n",
    "  metrics(truth = type, estimate = .pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References: \n",
    "Statista. (2021). Facebook: Monthly Active Users 2021. Retrieved on February 28, 2021 from http://www.statista.com.ezproxy.library.ubc.ca/statistics/264810/number-of-monthly-active-facebook-users-worldwide/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
